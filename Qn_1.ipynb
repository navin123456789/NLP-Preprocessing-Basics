{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Use library is NLTK for task"
      ],
      "metadata": {
        "id": "L0iqiGhu7iWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For NLTK\n",
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('maxent_ne_chunker_tab')\n",
        "nltk.download('words')\n",
        "\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk import pos_tag, ne_chunk\n",
        "\n",
        "text = \"I’m just someone who’s super curious about how tech works and how it can be used to make life easier or more meaningful. I really like exploring stuff like machine learning and AI, and I’ve been diving into things like music genre classification and even making a chatbot that talks like the Bhagavad Gita. It’s kinda crazy how much you can do with deep learning and all these tools like CNNs, transformers and other models I didn’t even knew existed few years ago. I’m also very into security – not just coding it but understanding how systems get attacked and how to protect them smartly. Ethics is a big thing for me too, cause like, what’s the point of building powerful tools if they’re used in wrong way, right? I also been trying to think more like a entrepreneur, trying to build stuff that people would actually use, like maintenance platforms and other ideas I’m still figuring out. I'm not perfect with everything I do, but I try, I learn, and I keep going. That’s kinda who I am.\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jq5vtpG59ICl",
        "outputId": "fb8385e9-47d3-4108-9550-439f0b0b07d6"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "\n"
      ],
      "metadata": {
        "id": "6DMIHdTE9xBx"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()  # Lowercase\n",
        "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
        "    text = re.sub(r'\\W', '', text)  # Remove special characters\n",
        "    return text"
      ],
      "metadata": {
        "id": "pv_CucwN9yUC"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "tokens = word_tokenize(text)\n",
        "print(\"Tokens:\", tokens)\n",
        "\n",
        "\n",
        "# POS Tagging\n",
        "pos_tags = pos_tag(tokens)\n",
        "print(\"POS Tags:\", pos_tags)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jD6J2tWA9a6v",
        "outputId": "baeab94f-293b-4238-e311-80c213f203cf"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['I', '’', 'm', 'just', 'someone', 'who', '’', 's', 'super', 'curious', 'about', 'how', 'tech', 'works', 'and', 'how', 'it', 'can', 'be', 'used', 'to', 'make', 'life', 'easier', 'or', 'more', 'meaningful', '.', 'I', 'really', 'like', 'exploring', 'stuff', 'like', 'machine', 'learning', 'and', 'AI', ',', 'and', 'I', '’', 've', 'been', 'diving', 'into', 'things', 'like', 'music', 'genre', 'classification', 'and', 'even', 'making', 'a', 'chatbot', 'that', 'talks', 'like', 'the', 'Bhagavad', 'Gita', '.', 'It', '’', 's', 'kinda', 'crazy', 'how', 'much', 'you', 'can', 'do', 'with', 'deep', 'learning', 'and', 'all', 'these', 'tools', 'like', 'CNNs', ',', 'transformers', 'and', 'other', 'models', 'I', 'didn', '’', 't', 'even', 'knew', 'existed', 'few', 'years', 'ago', '.', 'I', '’', 'm', 'also', 'very', 'into', 'security', '–', 'not', 'just', 'coding', 'it', 'but', 'understanding', 'how', 'systems', 'get', 'attacked', 'and', 'how', 'to', 'protect', 'them', 'smartly', '.', 'Ethics', 'is', 'a', 'big', 'thing', 'for', 'me', 'too', ',', 'cause', 'like', ',', 'what', '’', 's', 'the', 'point', 'of', 'building', 'powerful', 'tools', 'if', 'they', '’', 're', 'used', 'in', 'wrong', 'way', ',', 'right', '?', 'I', 'also', 'been', 'trying', 'to', 'think', 'more', 'like', 'a', 'entrepreneur', ',', 'trying', 'to', 'build', 'stuff', 'that', 'people', 'would', 'actually', 'use', ',', 'like', 'maintenance', 'platforms', 'and', 'other', 'ideas', 'I', '’', 'm', 'still', 'figuring', 'out', '.', 'I', \"'m\", 'not', 'perfect', 'with', 'everything', 'I', 'do', ',', 'but', 'I', 'try', ',', 'I', 'learn', ',', 'and', 'I', 'keep', 'going', '.', 'That', '’', 's', 'kinda', 'who', 'I', 'am', '.']\n",
            "POS Tags: [('I', 'PRP'), ('’', 'VBP'), ('m', 'RB'), ('just', 'RB'), ('someone', 'NN'), ('who', 'WP'), ('’', 'VBP'), ('s', 'JJ'), ('super', 'JJ'), ('curious', 'JJ'), ('about', 'IN'), ('how', 'WRB'), ('tech', 'JJ'), ('works', 'NNS'), ('and', 'CC'), ('how', 'WRB'), ('it', 'PRP'), ('can', 'MD'), ('be', 'VB'), ('used', 'VBN'), ('to', 'TO'), ('make', 'VB'), ('life', 'NN'), ('easier', 'JJR'), ('or', 'CC'), ('more', 'RBR'), ('meaningful', 'JJ'), ('.', '.'), ('I', 'PRP'), ('really', 'RB'), ('like', 'IN'), ('exploring', 'VBG'), ('stuff', 'NN'), ('like', 'IN'), ('machine', 'NN'), ('learning', 'NN'), ('and', 'CC'), ('AI', 'NNP'), (',', ','), ('and', 'CC'), ('I', 'PRP'), ('’', 'VBP'), ('ve', 'RB'), ('been', 'VBN'), ('diving', 'VBG'), ('into', 'IN'), ('things', 'NNS'), ('like', 'IN'), ('music', 'NN'), ('genre', 'NN'), ('classification', 'NN'), ('and', 'CC'), ('even', 'RB'), ('making', 'VBG'), ('a', 'DT'), ('chatbot', 'NN'), ('that', 'WDT'), ('talks', 'NNS'), ('like', 'IN'), ('the', 'DT'), ('Bhagavad', 'NNP'), ('Gita', 'NNP'), ('.', '.'), ('It', 'PRP'), ('’', 'VBD'), ('s', 'JJ'), ('kinda', 'NN'), ('crazy', 'VB'), ('how', 'WRB'), ('much', 'JJ'), ('you', 'PRP'), ('can', 'MD'), ('do', 'VB'), ('with', 'IN'), ('deep', 'JJ'), ('learning', 'NN'), ('and', 'CC'), ('all', 'PDT'), ('these', 'DT'), ('tools', 'NNS'), ('like', 'IN'), ('CNNs', 'NNP'), (',', ','), ('transformers', 'NNS'), ('and', 'CC'), ('other', 'JJ'), ('models', 'NNS'), ('I', 'PRP'), ('didn', 'VBP'), ('’', 'JJ'), ('t', 'NN'), ('even', 'RB'), ('knew', 'VBD'), ('existed', 'VBN'), ('few', 'JJ'), ('years', 'NNS'), ('ago', 'RB'), ('.', '.'), ('I', 'PRP'), ('’', 'VBP'), ('m', 'NNS'), ('also', 'RB'), ('very', 'RB'), ('into', 'IN'), ('security', 'NN'), ('–', 'NNP'), ('not', 'RB'), ('just', 'RB'), ('coding', 'VBG'), ('it', 'PRP'), ('but', 'CC'), ('understanding', 'VBG'), ('how', 'WRB'), ('systems', 'NNS'), ('get', 'VBP'), ('attacked', 'VBN'), ('and', 'CC'), ('how', 'WRB'), ('to', 'TO'), ('protect', 'VB'), ('them', 'PRP'), ('smartly', 'RB'), ('.', '.'), ('Ethics', 'NNS'), ('is', 'VBZ'), ('a', 'DT'), ('big', 'JJ'), ('thing', 'NN'), ('for', 'IN'), ('me', 'PRP'), ('too', 'RB'), (',', ','), ('cause', 'NN'), ('like', 'IN'), (',', ','), ('what', 'WP'), ('’', 'VBD'), ('s', 'PDT'), ('the', 'DT'), ('point', 'NN'), ('of', 'IN'), ('building', 'VBG'), ('powerful', 'JJ'), ('tools', 'NNS'), ('if', 'IN'), ('they', 'PRP'), ('’', 'VBP'), ('re', 'NNS'), ('used', 'VBN'), ('in', 'IN'), ('wrong', 'JJ'), ('way', 'NN'), (',', ','), ('right', 'RB'), ('?', '.'), ('I', 'PRP'), ('also', 'RB'), ('been', 'VBN'), ('trying', 'VBG'), ('to', 'TO'), ('think', 'VB'), ('more', 'RBR'), ('like', 'IN'), ('a', 'DT'), ('entrepreneur', 'NN'), (',', ','), ('trying', 'VBG'), ('to', 'TO'), ('build', 'VB'), ('stuff', 'NN'), ('that', 'IN'), ('people', 'NNS'), ('would', 'MD'), ('actually', 'RB'), ('use', 'VB'), (',', ','), ('like', 'IN'), ('maintenance', 'NN'), ('platforms', 'NNS'), ('and', 'CC'), ('other', 'JJ'), ('ideas', 'NNS'), ('I', 'PRP'), ('’', 'VBP'), ('m', 'NNS'), ('still', 'RB'), ('figuring', 'VBG'), ('out', 'RP'), ('.', '.'), ('I', 'PRP'), (\"'m\", 'VBP'), ('not', 'RB'), ('perfect', 'JJ'), ('with', 'IN'), ('everything', 'NN'), ('I', 'PRP'), ('do', 'VBP'), (',', ','), ('but', 'CC'), ('I', 'PRP'), ('try', 'VBP'), (',', ','), ('I', 'PRP'), ('learn', 'VBP'), (',', ','), ('and', 'CC'), ('I', 'PRP'), ('keep', 'VBP'), ('going', 'VBG'), ('.', '.'), ('That', 'DT'), ('’', 'VBZ'), ('s', 'JJ'), ('kinda', 'NN'), ('who', 'WP'), ('I', 'PRP'), ('am', 'VBP'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stemming\n",
        "stemmer = PorterStemmer()\n",
        "stems = [stemmer.stem(token) for token in tokens]\n",
        "print(\"Stemming:\", stems)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooCFehkH9cRH",
        "outputId": "b08f6f64-9d15-419e-8473-e88bbcacf62b"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stemming: ['i', '’', 'm', 'just', 'someon', 'who', '’', 's', 'super', 'curiou', 'about', 'how', 'tech', 'work', 'and', 'how', 'it', 'can', 'be', 'use', 'to', 'make', 'life', 'easier', 'or', 'more', 'meaning', '.', 'i', 'realli', 'like', 'explor', 'stuff', 'like', 'machin', 'learn', 'and', 'ai', ',', 'and', 'i', '’', 've', 'been', 'dive', 'into', 'thing', 'like', 'music', 'genr', 'classif', 'and', 'even', 'make', 'a', 'chatbot', 'that', 'talk', 'like', 'the', 'bhagavad', 'gita', '.', 'it', '’', 's', 'kinda', 'crazi', 'how', 'much', 'you', 'can', 'do', 'with', 'deep', 'learn', 'and', 'all', 'these', 'tool', 'like', 'cnn', ',', 'transform', 'and', 'other', 'model', 'i', 'didn', '’', 't', 'even', 'knew', 'exist', 'few', 'year', 'ago', '.', 'i', '’', 'm', 'also', 'veri', 'into', 'secur', '–', 'not', 'just', 'code', 'it', 'but', 'understand', 'how', 'system', 'get', 'attack', 'and', 'how', 'to', 'protect', 'them', 'smartli', '.', 'ethic', 'is', 'a', 'big', 'thing', 'for', 'me', 'too', ',', 'caus', 'like', ',', 'what', '’', 's', 'the', 'point', 'of', 'build', 'power', 'tool', 'if', 'they', '’', 're', 'use', 'in', 'wrong', 'way', ',', 'right', '?', 'i', 'also', 'been', 'tri', 'to', 'think', 'more', 'like', 'a', 'entrepreneur', ',', 'tri', 'to', 'build', 'stuff', 'that', 'peopl', 'would', 'actual', 'use', ',', 'like', 'mainten', 'platform', 'and', 'other', 'idea', 'i', '’', 'm', 'still', 'figur', 'out', '.', 'i', \"'m\", 'not', 'perfect', 'with', 'everyth', 'i', 'do', ',', 'but', 'i', 'tri', ',', 'i', 'learn', ',', 'and', 'i', 'keep', 'go', '.', 'that', '’', 's', 'kinda', 'who', 'i', 'am', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmas = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "print(\"Lemmatization:\", lemmas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_HoJgVP9dhV",
        "outputId": "9711b7d8-6cd7-4c74-f843-6239d7036261"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatization: ['I', '’', 'm', 'just', 'someone', 'who', '’', 's', 'super', 'curious', 'about', 'how', 'tech', 'work', 'and', 'how', 'it', 'can', 'be', 'used', 'to', 'make', 'life', 'easier', 'or', 'more', 'meaningful', '.', 'I', 'really', 'like', 'exploring', 'stuff', 'like', 'machine', 'learning', 'and', 'AI', ',', 'and', 'I', '’', 've', 'been', 'diving', 'into', 'thing', 'like', 'music', 'genre', 'classification', 'and', 'even', 'making', 'a', 'chatbot', 'that', 'talk', 'like', 'the', 'Bhagavad', 'Gita', '.', 'It', '’', 's', 'kinda', 'crazy', 'how', 'much', 'you', 'can', 'do', 'with', 'deep', 'learning', 'and', 'all', 'these', 'tool', 'like', 'CNNs', ',', 'transformer', 'and', 'other', 'model', 'I', 'didn', '’', 't', 'even', 'knew', 'existed', 'few', 'year', 'ago', '.', 'I', '’', 'm', 'also', 'very', 'into', 'security', '–', 'not', 'just', 'coding', 'it', 'but', 'understanding', 'how', 'system', 'get', 'attacked', 'and', 'how', 'to', 'protect', 'them', 'smartly', '.', 'Ethics', 'is', 'a', 'big', 'thing', 'for', 'me', 'too', ',', 'cause', 'like', ',', 'what', '’', 's', 'the', 'point', 'of', 'building', 'powerful', 'tool', 'if', 'they', '’', 're', 'used', 'in', 'wrong', 'way', ',', 'right', '?', 'I', 'also', 'been', 'trying', 'to', 'think', 'more', 'like', 'a', 'entrepreneur', ',', 'trying', 'to', 'build', 'stuff', 'that', 'people', 'would', 'actually', 'use', ',', 'like', 'maintenance', 'platform', 'and', 'other', 'idea', 'I', '’', 'm', 'still', 'figuring', 'out', '.', 'I', \"'m\", 'not', 'perfect', 'with', 'everything', 'I', 'do', ',', 'but', 'I', 'try', ',', 'I', 'learn', ',', 'and', 'I', 'keep', 'going', '.', 'That', '’', 's', 'kinda', 'who', 'I', 'am', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NER\n",
        "ner_tree = ne_chunk(pos_tags)\n",
        "print(\"Named Entities (NLTK):\")\n",
        "print(ner_tree)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpR6zKP09fGF",
        "outputId": "8db39aa2-c9b8-499d-d0d5-7ce447a4042d"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Named Entities (NLTK):\n",
            "(S\n",
            "  I/PRP\n",
            "  ’/VBP\n",
            "  m/RB\n",
            "  just/RB\n",
            "  someone/NN\n",
            "  who/WP\n",
            "  ’/VBP\n",
            "  s/JJ\n",
            "  super/JJ\n",
            "  curious/JJ\n",
            "  about/IN\n",
            "  how/WRB\n",
            "  tech/JJ\n",
            "  works/NNS\n",
            "  and/CC\n",
            "  how/WRB\n",
            "  it/PRP\n",
            "  can/MD\n",
            "  be/VB\n",
            "  used/VBN\n",
            "  to/TO\n",
            "  make/VB\n",
            "  life/NN\n",
            "  easier/JJR\n",
            "  or/CC\n",
            "  more/RBR\n",
            "  meaningful/JJ\n",
            "  ./.\n",
            "  I/PRP\n",
            "  really/RB\n",
            "  like/IN\n",
            "  exploring/VBG\n",
            "  stuff/NN\n",
            "  like/IN\n",
            "  machine/NN\n",
            "  learning/NN\n",
            "  and/CC\n",
            "  (ORGANIZATION AI/NNP)\n",
            "  ,/,\n",
            "  and/CC\n",
            "  I/PRP\n",
            "  ’/VBP\n",
            "  ve/RB\n",
            "  been/VBN\n",
            "  diving/VBG\n",
            "  into/IN\n",
            "  things/NNS\n",
            "  like/IN\n",
            "  music/NN\n",
            "  genre/NN\n",
            "  classification/NN\n",
            "  and/CC\n",
            "  even/RB\n",
            "  making/VBG\n",
            "  a/DT\n",
            "  chatbot/NN\n",
            "  that/WDT\n",
            "  talks/NNS\n",
            "  like/IN\n",
            "  the/DT\n",
            "  (ORGANIZATION Bhagavad/NNP Gita/NNP)\n",
            "  ./.\n",
            "  It/PRP\n",
            "  ’/VBD\n",
            "  s/JJ\n",
            "  kinda/NN\n",
            "  crazy/VB\n",
            "  how/WRB\n",
            "  much/JJ\n",
            "  you/PRP\n",
            "  can/MD\n",
            "  do/VB\n",
            "  with/IN\n",
            "  deep/JJ\n",
            "  learning/NN\n",
            "  and/CC\n",
            "  all/PDT\n",
            "  these/DT\n",
            "  tools/NNS\n",
            "  like/IN\n",
            "  (ORGANIZATION CNNs/NNP)\n",
            "  ,/,\n",
            "  transformers/NNS\n",
            "  and/CC\n",
            "  other/JJ\n",
            "  models/NNS\n",
            "  I/PRP\n",
            "  didn/VBP\n",
            "  ’/JJ\n",
            "  t/NN\n",
            "  even/RB\n",
            "  knew/VBD\n",
            "  existed/VBN\n",
            "  few/JJ\n",
            "  years/NNS\n",
            "  ago/RB\n",
            "  ./.\n",
            "  I/PRP\n",
            "  ’/VBP\n",
            "  m/NNS\n",
            "  also/RB\n",
            "  very/RB\n",
            "  into/IN\n",
            "  security/NN\n",
            "  –/NNP\n",
            "  not/RB\n",
            "  just/RB\n",
            "  coding/VBG\n",
            "  it/PRP\n",
            "  but/CC\n",
            "  understanding/VBG\n",
            "  how/WRB\n",
            "  systems/NNS\n",
            "  get/VBP\n",
            "  attacked/VBN\n",
            "  and/CC\n",
            "  how/WRB\n",
            "  to/TO\n",
            "  protect/VB\n",
            "  them/PRP\n",
            "  smartly/RB\n",
            "  ./.\n",
            "  Ethics/NNS\n",
            "  is/VBZ\n",
            "  a/DT\n",
            "  big/JJ\n",
            "  thing/NN\n",
            "  for/IN\n",
            "  me/PRP\n",
            "  too/RB\n",
            "  ,/,\n",
            "  cause/NN\n",
            "  like/IN\n",
            "  ,/,\n",
            "  what/WP\n",
            "  ’/VBD\n",
            "  s/PDT\n",
            "  the/DT\n",
            "  point/NN\n",
            "  of/IN\n",
            "  building/VBG\n",
            "  powerful/JJ\n",
            "  tools/NNS\n",
            "  if/IN\n",
            "  they/PRP\n",
            "  ’/VBP\n",
            "  re/NNS\n",
            "  used/VBN\n",
            "  in/IN\n",
            "  wrong/JJ\n",
            "  way/NN\n",
            "  ,/,\n",
            "  right/RB\n",
            "  ?/.\n",
            "  I/PRP\n",
            "  also/RB\n",
            "  been/VBN\n",
            "  trying/VBG\n",
            "  to/TO\n",
            "  think/VB\n",
            "  more/RBR\n",
            "  like/IN\n",
            "  a/DT\n",
            "  entrepreneur/NN\n",
            "  ,/,\n",
            "  trying/VBG\n",
            "  to/TO\n",
            "  build/VB\n",
            "  stuff/NN\n",
            "  that/IN\n",
            "  people/NNS\n",
            "  would/MD\n",
            "  actually/RB\n",
            "  use/VB\n",
            "  ,/,\n",
            "  like/IN\n",
            "  maintenance/NN\n",
            "  platforms/NNS\n",
            "  and/CC\n",
            "  other/JJ\n",
            "  ideas/NNS\n",
            "  I/PRP\n",
            "  ’/VBP\n",
            "  m/NNS\n",
            "  still/RB\n",
            "  figuring/VBG\n",
            "  out/RP\n",
            "  ./.\n",
            "  I/PRP\n",
            "  'm/VBP\n",
            "  not/RB\n",
            "  perfect/JJ\n",
            "  with/IN\n",
            "  everything/NN\n",
            "  I/PRP\n",
            "  do/VBP\n",
            "  ,/,\n",
            "  but/CC\n",
            "  I/PRP\n",
            "  try/VBP\n",
            "  ,/,\n",
            "  I/PRP\n",
            "  learn/VBP\n",
            "  ,/,\n",
            "  and/CC\n",
            "  I/PRP\n",
            "  keep/VBP\n",
            "  going/VBG\n",
            "  ./.\n",
            "  That/DT\n",
            "  ’/VBZ\n",
            "  s/JJ\n",
            "  kinda/NN\n",
            "  who/WP\n",
            "  I/PRP\n",
            "  am/VBP\n",
            "  ./.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare lemmatization and stemming with at least 10 examples and explain the\n",
        "differences."
      ],
      "metadata": {
        "id": "tqZzOPPl9iAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "words = [\"running\", \"flies\", \"better\", \"cities\", \"caring\", \"played\", \"mice\", \"feet\", \"geese\", \"wolves\"]\n",
        "print(f\"{'Word':<10}{'Stem':<15}{'Lemma':<15}\")\n",
        "print(\"-\" * 40)\n",
        "for word in words:\n",
        "    stem = stemmer.stem(word)\n",
        "    lemma = lemmatizer.lemmatize(word)\n",
        "    print(f\"{word:<10}{stem:<15}{lemma:<15}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1dboZn09Wvg",
        "outputId": "efb33177-a77e-4175-8834-2836bfdb2a13"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word      Stem           Lemma          \n",
            "----------------------------------------\n",
            "running   run            running        \n",
            "flies     fli            fly            \n",
            "better    better         better         \n",
            "cities    citi           city           \n",
            "caring    care           caring         \n",
            "played    play           played         \n",
            "mice      mice           mouse          \n",
            "feet      feet           foot           \n",
            "geese     gees           goose          \n",
            "wolves    wolv           wolf           \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let’s talk about the differences**\n",
        "\n",
        "1. Stemming is like cutting corners\n",
        "Stemming is more of a quick and dirty method. It just chops off the ends of words most of the time, without caring if the result is an actual word. Like with flies, it becomes fli, which doesn’t really make sense on its own. It’s just removing the -es and assuming it helps.\n",
        "\n",
        "2. Lemmatization cares more about the meaning\n",
        "Lemmatization, on the other hand, tries to find the actual root word that has meaning in grammar. So flies becomes fly, which is a proper word. Same with mice, it turns into mouse — which is the correct singular form.\n",
        "\n",
        "3. Lemmatization needs more info\n",
        "Unlike stemming, lemmatization sometimes needs the context or part of speech to do its job right. For example, better could be an adjective or a verb. It stays the same unless you provide extra information.\n",
        "\n",
        "4. Stemming is faster but less accurate\n",
        "Because stemming is simple and rule-based, it's faster, but sometimes it produces words that aren't real (like citi, gees, wolv). Lemmatization is more reliable but a bit slower.\n"
      ],
      "metadata": {
        "id": "dON4skIi_F54"
      }
    }
  ]
}